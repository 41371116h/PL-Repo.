{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/41371116h/PL-Repo./blob/main/HW6%E8%AA%B2%E8%A1%A8%E6%9F%A5%E8%A9%A2%E7%B3%BB%E7%B5%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#HW6èª²è¡¨æŸ¥è©¢ç³»çµ±ï¼ˆä½œæ¥­å…­ï¼‰\n",
        "- GoogleSheet: https://docs.google.com/spreadsheets/d/1guxOJTsJ2nPqzGPiqHkalhFyv3W66Yl0tLPzz3gmEjk/edit?gid=270672772#gid=270672772"
      ],
      "metadata": {
        "id": "gmimRU69FIrL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ8s5cyrYefr",
        "outputId": "56b743d6-9853-41b1-b6d9-f0885a17f5f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ç•¶å‰ HTTP_PROXY: None\n",
            "ç•¶å‰ HTTPS_PROXY: None\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# æª¢æŸ¥æ˜¯å¦å­˜åœ¨ä»£ç†è®Šæ•¸\n",
        "print(\"ç•¶å‰ HTTP_PROXY:\", os.environ.get('HTTP_PROXY'))\n",
        "print(\"ç•¶å‰ HTTPS_PROXY:\", os.environ.get('HTTPS_PROXY'))\n",
        "\n",
        "# æ¸…é™¤ä»£ç†è®Šæ•¸\n",
        "if 'HTTP_PROXY' in os.environ:\n",
        "    del os.environ['HTTP_PROXY']\n",
        "    print(\"å·²æ¸…é™¤ HTTP_PROXY\")\n",
        "if 'HTTPS_PROXY' in os.environ:\n",
        "    del os.environ['HTTPS_PROXY']\n",
        "    print(\"å·²æ¸…é™¤ HTTPS_PROXY\")\n",
        "if 'http_proxy' in os.environ:\n",
        "    del os.environ['http_proxy']\n",
        "    print(\"å·²æ¸…é™¤ http_proxy (å°å¯«)\")\n",
        "if 'https_proxy' in os.environ:\n",
        "    del os.environ['https_proxy']\n",
        "    print(\"å·²æ¸…é™¤ https_proxy (å°å¯«)\")\n",
        "\n",
        "# é‡æ–°å•Ÿå‹•æ‚¨çš„ Gradio æ‡‰ç”¨ç¨‹å¼\n",
        "# æ¥è‘—åŸ·è¡Œ genai.configure() å’Œ demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jC3gbWq9ZEJK"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth, userdata\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUotyOV0ZGLd",
        "outputId": "20d48cfd-fda5-4c76-f3df-71def55bae0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.49.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.121.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.13.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.13.3)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.4)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.49.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4-wzGybktOI",
        "outputId": "58d37b6d-9c45-4d33-b30b-973686229f3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-6.2.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Downloading pypdf-6.2.0-py3-none-any.whl (326 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m326.6/326.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-6.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# ğŸ“ æ™ºæ…§èª²è¡¨æŸ¥çœ‹ç³»çµ±ï¼ˆGradio + Google Sheets + PDF è§£æä¸Šå‚³ï¼‰\n",
        "# =========================================================\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import pytz\n",
        "import gradio as gr\n",
        "import google.generativeai as genai\n",
        "import io\n",
        "import traceback\n",
        "import json # ç”¨æ–¼åœ¨ Gradio state ä¸­å‚³è¼¸ DataFrame\n",
        "import textwrap # æ–°å¢ï¼šç”¨æ–¼æ–‡æœ¬æ›è¡Œè™•ç†\n",
        "\n",
        "# å˜—è©¦å°å…¥ pypdf é€²è¡Œ PDF è®€å–\n",
        "try:\n",
        "    from pypdf import PdfReader\n",
        "except ImportError:\n",
        "    PdfReader = None\n",
        "    print(\"âš ï¸ ç¼ºå°‘ pypdf å‡½å¼åº«ï¼ŒPDF è§£æåŠŸèƒ½å°‡ç„¡æ³•é‹ä½œã€‚è«‹åœ¨ Colab ä¸­åŸ·è¡Œ !pip install pypdf\")\n",
        "\n",
        "# === Google Sheets è¨­å®šèˆ‡é€£ç·š ===\n",
        "SHEET_URL = \"https://docs.google.com/spreadsheets/d/1guxOJTsJ2nPqzGPiqHkalhFyv3W66Yl0tLPzz3gmEjk/edit?gid=270672772#gid=270672772\"\n",
        "WORKSHEET_NAME = \"èª²è¡¨\"\n",
        "SHEET_WEEKLY = \"æœ¬é€±é‡é»\"\n",
        "SHEET_GEMINI_SUGGESTION = \"Geminiå»ºè­°\"\n",
        "SHEET_UPLOAD_NEW = \"ä¸Šå‚³æ–°èª²è¡¨\"\n",
        "TIMEZONE = \"Asia/Taipei\"\n",
        "\n",
        "worksheet = None\n",
        "suggestion_ws = None\n",
        "new_timetable_ws = None\n",
        "weekly_ws = None # æœ¬é€±é‡é»å·¥ä½œè¡¨\n",
        "\n",
        "# ç¢ºä¿ WEEKLY è¡¨é ­**åš´æ ¼**æŒ‰ç…§ç”¨æˆ¶è¦æ±‚çš„é †åº\n",
        "# é€±æ¬¡èµ·è¨– æŸ¥è©¢æ˜ŸæœŸ ç•¶æ—¥èª²ç¨‹åˆ—è¡¨ æ›´æ–°æ™‚é–“ è¡Œå‰æé†’ä¸€å¥è©± èª²ç¨‹æ‘˜è¦ AIå­¸ç¿’å»ºè­° æ”œå¸¶å“ å…ˆè®€ç« ç¯€\n",
        "WEEKLY_HEADER = [\n",
        "    \"é€±æ¬¡èµ·è¨–\", \"æŸ¥è©¢æ˜ŸæœŸ\", \"ç•¶æ—¥èª²ç¨‹åˆ—è¡¨\", \"æ›´æ–°æ™‚é–“\",\n",
        "    \"è¡Œå‰æé†’ä¸€å¥è©±\", \"èª²ç¨‹æ‘˜è¦\", \"AIå­¸ç¿’å»ºè­°\", \"æ”œå¸¶å“\", \"å…ˆè®€ç« ç¯€\"\n",
        "]\n",
        "\n",
        "try:\n",
        "    creds, _ = default()\n",
        "    gc = gspread.authorize(creds)\n",
        "    gsheets = gc.open_by_url(SHEET_URL)\n",
        "    worksheet = gsheets.worksheet(WORKSHEET_NAME) # èª²è¡¨å·¥ä½œè¡¨\n",
        "\n",
        "    # é€£ç·šæˆ–å»ºç«‹å»ºè­°åˆ†é \n",
        "    try:\n",
        "        suggestion_ws = gsheets.worksheet(SHEET_GEMINI_SUGGESTION)\n",
        "    except gspread.WorksheetNotFound:\n",
        "        suggestion_ws = gsheets.add_worksheet(title=SHEET_GEMINI_SUGGESTION, rows=\"200\", cols=\"3\")\n",
        "        suggestion_ws.append_row([\"æ™‚é–“\", \"åˆ†æå°è±¡\", \"Gemini å»ºè­°/éŒ¯èª¤è¨Šæ¯\"], value_input_option=\"USER_ENTERED\")\n",
        "\n",
        "    # é€£ç·šæˆ–å»ºç«‹ä¸Šå‚³æ–°èª²è¡¨åˆ†é \n",
        "    try:\n",
        "        new_timetable_ws = gsheets.worksheet(SHEET_UPLOAD_NEW)\n",
        "    except gspread.WorksheetNotFound:\n",
        "        NEW_HEADER = [\"èª²ç¨‹åç¨±\", \"ä¸Šèª²æ•™å®¤\", \"æ˜ŸæœŸ\", \"ç¯€æ¬¡\", \"ä¸Šèª²æ™‚é–“\"]\n",
        "        new_timetable_ws = gsheets.add_worksheet(title=SHEET_UPLOAD_NEW, rows=\"500\", cols=len(NEW_HEADER))\n",
        "        new_timetable_ws.append_row(NEW_HEADER, value_input_option=\"USER_ENTERED\")\n",
        "\n",
        "    # é€£ç·šæˆ–å»ºç«‹æœ¬é€±é‡é»åˆ†é  (ä¸¦ç¢ºä¿æ¬„ä½é½Šå…¨)\n",
        "    try:\n",
        "        weekly_ws = gsheets.worksheet(SHEET_WEEKLY)\n",
        "        # ç°¡æ˜“æª¢æŸ¥è¡¨é ­ï¼Œè‹¥ä¸ä¸€è‡´å‰‡æé†’ï¼ˆé€™è£¡ä¸è‡ªå‹•ä¿®æ”¹ï¼Œé¿å…è¦†è“‹ç”¨æˆ¶æ•¸æ“šï¼Œåƒ…æ‰“å°æç¤ºï¼‰\n",
        "        current_header = weekly_ws.row_values(1)\n",
        "        if current_header != WEEKLY_HEADER:\n",
        "            print(f\"âš ï¸ '{SHEET_WEEKLY}' è¡¨é ­ä¸ç¬¦é æœŸã€‚è«‹æ‰‹å‹•ä¿®æ”¹ç‚º: {WEEKLY_HEADER}\")\n",
        "    except gspread.WorksheetNotFound:\n",
        "        weekly_ws = gsheets.add_worksheet(title=SHEET_WEEKLY, rows=\"100\", cols=len(WEEKLY_HEADER))\n",
        "        weekly_ws.append_row(WEEKLY_HEADER, value_input_option=\"USER_ENTERED\")\n",
        "\n",
        "    print(f\"âœ… Google Sheets é€£ç·šæˆåŠŸã€‚\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Google Sheets é€£ç·šæˆ–è¨­ç½®å¤±æ•—: {e}\")\n",
        "\n",
        "TW_TZ = pytz.timezone(TIMEZONE)\n",
        "\n",
        "# === Gemini API è¨­å®š ===\n",
        "try:\n",
        "    genai.configure(api_key=\"AIzaSyAWyvSMGkAgiTMSdE8TEId8IFDw0OD46io\")\n",
        "    model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
        "    print(\"âœ… Gemini API é…ç½®æˆåŠŸã€‚\")\n",
        "except Exception as e:\n",
        "    model = None\n",
        "    print(f\"âŒ Gemini API é…ç½®å¤±æ•—: {e}\")\n",
        "\n",
        "\n",
        "# === å·¥å…·å‡½å¼ ===\n",
        "week_map_tw = {\"ä¸€\":0,\"äºŒ\":1,\"ä¸‰\":2,\"å››\":3,\"äº”\":4,\"å…­\":5,\"æ—¥\":6}\n",
        "\n",
        "def normalize_weekday(w):\n",
        "    if w in week_map_tw: return week_map_tw[w]\n",
        "    raise ValueError(\"æ˜ŸæœŸè«‹ç”¨ï¼šä¸€~æ—¥\")\n",
        "\n",
        "def week_monday(any_date):\n",
        "    return any_date - dt.timedelta(days=any_date.weekday())\n",
        "\n",
        "def date_range_this_week(today=None):\n",
        "    now = dt.datetime.now(TW_TZ).date() if today is None else today\n",
        "    mon = week_monday(now)\n",
        "    sun = mon + dt.timedelta(days=6)\n",
        "    return mon, sun\n",
        "\n",
        "# --- Text Wrapping Helper Function ---\n",
        "def wrap_text(text, limit=15):\n",
        "    \"\"\"å°‡é•·æ–‡æœ¬åœ¨ 15 å€‹å­—ç¬¦å¾Œæ›è¡Œï¼Œä¸¦ä¿ç•™åŸå§‹æ›è¡Œã€‚\"\"\"\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return text\n",
        "\n",
        "    paragraphs = text.split('\\n')\n",
        "    wrapped_content = []\n",
        "    for para in paragraphs:\n",
        "        if para.strip():\n",
        "            # ä½¿ç”¨ textwrap.fill å¯¦ç¾è‡ªå‹•æ›è¡Œ\n",
        "            wrapped_content.append(textwrap.fill(para, width=limit, subsequent_indent=''))\n",
        "        else:\n",
        "            wrapped_content.append('')\n",
        "    return '\\n'.join(wrapped_content)\n",
        "\n",
        "def summarize_courses(day_df, format_type='detailed'):\n",
        "    \"\"\"æ•´ç†èª²ç¨‹æ–‡å­—å…§å®¹ï¼Œæ–°å¢ç¬¦åˆç”¨æˆ¶è¦æ±‚ä¹‹è©³ç´°æ ¼å¼ã€‚\"\"\"\n",
        "    if day_df.empty:\n",
        "        return \"æœ¬æ—¥ç„¡èª²\"\n",
        "\n",
        "    parts = []\n",
        "\n",
        "    if format_type == 'detailed':\n",
        "        # ç”¨æˆ¶è¦æ±‚çš„æ ¼å¼: èª²ç¨‹åç¨±ä¸Šèª²æ•™å®¤æ˜ŸæœŸç¯€æ¬¡ä¸Šèª²æ™‚é–“\n",
        "        for _, r in day_df.iterrows():\n",
        "            name = r.get(\"èª²ç¨‹åç¨±\", \"\")\n",
        "            room = r.get(\"ä¸Šèª²æ•™å®¤\", \"\")\n",
        "            day = r.get(\"æ˜ŸæœŸ\", \"\")\n",
        "            lesson = r.get(\"ç¯€æ¬¡\", \"\")\n",
        "            time = r.get(\"ä¸Šèª²æ™‚é–“\", \"\")\n",
        "            # ç¯„ä¾‹: æ©Ÿæ¢°è£½é€ ç§‘æŠ€ç³»TC504æ•™å®¤ä¸€108:10 - 09:00\n",
        "            parts.append(f\"{name}{room}æ•™å®¤{day}{lesson}{time}\")\n",
        "        return \"\\n\".join(parts) # Gradio é¡¯ç¤ºç”¨ï¼Œæ›è¡Œåˆ†éš”\n",
        "\n",
        "    elif format_type == 'sheet_raw_items':\n",
        "        # ç‚ºäº†å¯«å…¥ Google Sheet æ•´ç†çš„åŸå§‹æ”œå¸¶å“èˆ‡å…ˆè®€ç« ç¯€åˆ—è¡¨\n",
        "        items = []\n",
        "        readings = []\n",
        "        for _, r in day_df.iterrows():\n",
        "            if str(r.get(\"æ”œå¸¶å“\", \"\")).strip():\n",
        "                items.append(str(r[\"æ”œå¸¶å“\"]).strip())\n",
        "            if str(r.get(\"å…ˆè®€ç« ç¯€\", \"\")).strip():\n",
        "                readings.append(str(r[\"å…ˆè®€ç« ç¯€\"]).strip())\n",
        "        # AI å»ºè­°å°‡è¦†è“‹é€™å…©å€‹æ¬„ä½ï¼Œé€™è£¡è¿”å›åŸå§‹æ•¸æ“š\n",
        "        items_txt = \"ï¼›\".join(dict.fromkeys(items)) if items else \"\"\n",
        "        read_txt  = \"ï¼›\".join(dict.fromkeys(readings)) if readings else \"\"\n",
        "        return items_txt, read_txt\n",
        "\n",
        "    return \"æœ¬æ—¥ç„¡èª²\"\n",
        "\n",
        "# === è¼”åŠ©å‡½å¼ï¼šæ›´æ–° Google Sheet (æœ¬é€±é‡é») (Upsert æ¨¡å¼) ===\n",
        "def update_weekly_sheet_row(target_weekday, row_data):\n",
        "    \"\"\"\n",
        "    å°‡ç•¶æ—¥æ‰€æœ‰æ•¸æ“šå¯«å…¥/æ›´æ–°åˆ° 'æœ¬é€±é‡é»' åˆ†é çš„è¨˜éŒ„ã€‚\n",
        "    - åŒä¸€é€±æ¬¡çš„åŒä¸€æ˜ŸæœŸï¼šæ›´æ–°ç¾æœ‰è¡Œã€‚\n",
        "    - ä¸åŒï¼šè¿½åŠ æ–°è¡Œã€‚\n",
        "    - ç¢ºä¿ç¬¬ä¸€åˆ— (è¡¨é ­) ä¸è¢«æ•¸æ“šè¦†è“‹ã€‚\n",
        "    \"\"\"\n",
        "    if not weekly_ws:\n",
        "        return \"âŒ Google Sheets 'æœ¬é€±é‡é»' æœªé€£ç·šã€‚\"\n",
        "\n",
        "    now_str = dt.datetime.now(TW_TZ).strftime(\"%Y-%m-%d %H:%M\")\n",
        "    today = dt.datetime.now(TW_TZ).date()\n",
        "    week_start, week_end = date_range_this_week(today)\n",
        "    current_date_range = f\"{week_start} ~ {week_end}\"\n",
        "    target_day_str = f\"æ˜ŸæœŸ{target_weekday}\"\n",
        "\n",
        "    # 1. è®€å–ç¾æœ‰æ•¸æ“š (åŒ…å«è¡¨é ­)\n",
        "    all_values = weekly_ws.get_all_values()\n",
        "\n",
        "    # åˆå§‹åŒ– DataFrame å’Œç‹€æ…‹\n",
        "    header = WEEKLY_HEADER\n",
        "    df_weekly = pd.DataFrame(columns=header)\n",
        "    status_action = \"æ–°å¢\"\n",
        "\n",
        "    # åŠ è¼‰ç¾æœ‰æ•¸æ“šåˆ° df_weekly (è·³éç¬¬ä¸€è¡Œ header)\n",
        "    if len(all_values) > 1:\n",
        "        header = all_values[0]\n",
        "        records = all_values[1:]\n",
        "        try:\n",
        "            df_weekly = pd.DataFrame(records, columns=header)\n",
        "        except ValueError:\n",
        "            # Fallback for mismatched columns\n",
        "            print(\"âš ï¸ è®€å– 'æœ¬é€±é‡é»' æ™‚ç™¼ç¾åˆ—æ•¸ä¸åŒ¹é…ï¼Œå˜—è©¦ç”¨è®€å–åˆ°çš„è¡¨é ­è™•ç†ã€‚\")\n",
        "            df_weekly = pd.DataFrame(records)\n",
        "            df_weekly.columns = header[:len(df_weekly.columns)] if records and records[0] else header\n",
        "    elif len(all_values) == 1:\n",
        "        # åªæœ‰è¡¨é ­\n",
        "        header = all_values[0]\n",
        "        df_weekly = pd.DataFrame(columns=header)\n",
        "\n",
        "\n",
        "    # 2. æº–å‚™æ›´æ–°å­—æ®µ\n",
        "    update_fields = {\"æ›´æ–°æ™‚é–“\": now_str}\n",
        "    update_fields.update(row_data) # è¦†è“‹å‚³å…¥çš„ row_data\n",
        "\n",
        "\n",
        "    # 3. Upsert é‚è¼¯ï¼šæª¢æŸ¥æ˜¯å¦å­˜åœ¨åŒ¹é…é … (é€±æ¬¡èµ·è¨– AND æŸ¥è©¢æ˜ŸæœŸ)\n",
        "    is_matched = False\n",
        "    write_df = df_weekly\n",
        "\n",
        "    match_cols_exist = \"é€±æ¬¡èµ·è¨–\" in df_weekly.columns and \"æŸ¥è©¢æ˜ŸæœŸ\" in df_weekly.columns\n",
        "\n",
        "    if match_cols_exist and not df_weekly.empty:\n",
        "\n",
        "        match_condition = (df_weekly[\"é€±æ¬¡èµ·è¨–\"] == current_date_range) & \\\n",
        "                          (df_weekly[\"æŸ¥è©¢æ˜ŸæœŸ\"] == target_day_str)\n",
        "\n",
        "        if match_condition.any():\n",
        "            # --- UPDATE MODE (æ›´æ–°æ¨¡å¼) ---\n",
        "            update_index_in_df = df_weekly[match_condition].index[-1]\n",
        "\n",
        "            # éæ­·è¦æ›´æ–°çš„å­—æ®µï¼Œåªæ›´æ–°éç©ºå€¼ï¼ˆæˆ–åŸºç¤æ•¸æ“šå­—æ®µï¼‰\n",
        "            for key, value in update_fields.items():\n",
        "                is_long_text_field = key in [\"ç•¶æ—¥èª²ç¨‹åˆ—è¡¨\", \"èª²ç¨‹æ‘˜è¦\", \"AIå­¸ç¿’å»ºè­°\"]\n",
        "                is_ai_result_field = key in [\"è¡Œå‰æé†’ä¸€å¥è©±\", \"æ”œå¸¶å“\", \"å…ˆè®€ç« ç¯€\"]\n",
        "\n",
        "                if key in df_weekly.columns and (is_long_text_field or is_ai_result_field or value != ''):\n",
        "                    # å…è¨± AI æ¬„ä½å’Œé•·æ–‡æœ¬æ¬„ä½å¯«å…¥ç©ºå€¼ï¼ˆå¦‚æœå‚³å…¥ç©ºå€¼å‰‡æ¸…ç©ºï¼‰\n",
        "                    df_weekly.loc[update_index_in_df, key] = value\n",
        "                elif key == \"æ›´æ–°æ™‚é–“\":\n",
        "                     df_weekly.loc[update_index_in_df, key] = value\n",
        "\n",
        "            write_df = df_weekly\n",
        "            status_action = \"æ›´æ–°\"\n",
        "            is_matched = True\n",
        "\n",
        "    if not is_matched:\n",
        "        # --- INSERT/APPEND MODE (æ–°å¢æ¨¡å¼) ---\n",
        "\n",
        "        # å¾é ­å»ºç«‹æ–°è¡Œæ•¸æ“šï¼Œç¢ºä¿æ‰€æœ‰å­—æ®µéƒ½æœ‰é»˜èªå€¼\n",
        "        new_row_data = {col: '' for col in WEEKLY_HEADER}\n",
        "        new_row_data.update(update_fields) # æ‡‰ç”¨æ‰€æœ‰æ›´æ–°\n",
        "        new_row_data[\"é€±æ¬¡èµ·è¨–\"] = current_date_range\n",
        "        new_row_data[\"æŸ¥è©¢æ˜ŸæœŸ\"] = target_day_str\n",
        "\n",
        "        df_new_row = pd.DataFrame([new_row_data], columns=WEEKLY_HEADER)\n",
        "\n",
        "        # é™„åŠ åˆ°ç¾æœ‰ DataFrame\n",
        "        if not df_weekly.empty and all(col in df_weekly.columns for col in WEEKLY_HEADER):\n",
        "             write_df = pd.concat([df_weekly[WEEKLY_HEADER], df_new_row], ignore_index=True)\n",
        "        else:\n",
        "             write_df = df_new_row # å¦‚æœåŸå§‹DFæœ‰å•é¡Œï¼Œå°±åªå¯«å…¥æ–°è¡Œ\n",
        "\n",
        "        status_action = \"æ–°å¢\"\n",
        "\n",
        "    # 4. å¯«å› Google Sheets (ç¢ºä¿ç¬¬ä¸€åˆ—ä¸è¦†è“‹)\n",
        "\n",
        "    # æ¸…é™¤æ‰€æœ‰æ•¸æ“š (å¾ç¬¬äºŒåˆ—é–‹å§‹)\n",
        "    if len(all_values) > 1:\n",
        "        # æ¸…é™¤å¾ Row 2 åˆ°æœ€å¾Œçš„æ•¸æ“š\n",
        "        weekly_ws.delete_rows(2, len(all_values))\n",
        "\n",
        "    # å¯«å…¥æ•¸æ“š (å¾ç¬¬äºŒåˆ—é–‹å§‹ï¼Œä¸åŒ…å«æ¬„ä½åç¨±)\n",
        "    if not write_df.empty:\n",
        "         # å¿…é ˆç¢ºä¿ DataFrame çš„åˆ—èˆ‡ç›®æ¨™ header ä¸€è‡´\n",
        "         write_df_cleaned = write_df.reindex(columns=WEEKLY_HEADER)\n",
        "         # row=2 ç¢ºä¿æ•¸æ“šå¾ç¬¬äºŒè¡Œé–‹å§‹å¯«å…¥ï¼Œä¿ç•™äº†ç¬¬ä¸€è¡Œ header çš„æ ¼å¼\n",
        "         set_with_dataframe(weekly_ws, write_df_cleaned, include_column_header=False, include_index=False, row=2)\n",
        "\n",
        "    return f\"âœ… '{SHEET_WEEKLY}' åˆ†é {status_action}æˆåŠŸï¼\"\n",
        "\n",
        "\n",
        "# === Gradio æ ¸å¿ƒé‚è¼¯ï¼šæŸ¥è©¢ç•¶æ—¥èª²è¡¨ (å·²èª¿æ•´) ===\n",
        "def query_day_data(target_weekday):\n",
        "    \"\"\"\n",
        "    æŸ¥è©¢æŒ‡å®šæ˜ŸæœŸçš„èª²ç¨‹ï¼Œä¸¦è¿”å›è©³ç´°åˆ—è¡¨å’Œåºåˆ—åŒ–çš„ DataFrame (ä¾› AI ä½¿ç”¨)ã€‚\n",
        "    åŒæ™‚å‰µå»ºè©²æ—¥çš„åŸºç¤è¨˜éŒ„ã€‚\n",
        "    \"\"\"\n",
        "    if not worksheet:\n",
        "        return \"âŒ Google Sheets æœªæˆåŠŸé€£ç·šï¼Œç„¡æ³•è®€å–è³‡æ–™ã€‚\", \"\", \"\"\n",
        "\n",
        "    try:\n",
        "        data = worksheet.get_all_values()\n",
        "        df = pd.DataFrame(data[1:], columns=data[0])\n",
        "    except Exception as e:\n",
        "        return f\"âŒ ç„¡æ³•è®€å–èª²è¡¨ï¼š{e}\", \"\", \"\"\n",
        "\n",
        "    # æ‰¾å‡ºè©²æ˜ŸæœŸçš„èª²ç¨‹\n",
        "    today_df = df[df[\"æ˜ŸæœŸ\"] == target_weekday].copy()\n",
        "\n",
        "    # æ ¼å¼åŒ–è©³ç´°èª²ç¨‹åˆ—è¡¨ (Gradio é¡¯ç¤ºç”¨)\n",
        "    detailed_list = summarize_courses(today_df, format_type='detailed')\n",
        "\n",
        "    if today_df.empty:\n",
        "        # å¦‚æœæœ¬æ—¥ç„¡èª²ï¼Œä»è¿”å›ç©º JSON ç‹€æ…‹\n",
        "        return f\"### ğŸ—“ï¸ æ˜ŸæœŸ{target_weekday} æœ¬æ—¥ç„¡èª²\", detailed_list, \"\"\n",
        "\n",
        "    # åºåˆ—åŒ– DataFrameï¼Œä»¥ä¾¿åœ¨ Gradio state ä¸­å‚³è¼¸\n",
        "    df_json = today_df.to_json(orient='records', force_ascii=False)\n",
        "\n",
        "    # ç²å–åŸå§‹æ”œå¸¶å“å’Œå…ˆè®€ç« ç¯€çš„åˆ—è¡¨ï¼Œä¾›å¯«å…¥ Google Sheet ä½¿ç”¨\n",
        "    items_txt, read_txt = summarize_courses(today_df, format_type='sheet_raw_items')\n",
        "\n",
        "    # å°‡åˆå§‹æ•¸æ“šå¯«å…¥ Sheet (å‰µå»ºæˆ–æ›¿æ›è©²æ—¥çš„è¨˜éŒ„)\n",
        "    row_data = {\n",
        "        # æ‡‰ç”¨æ›è¡Œï¼Œä¸¦å°‡æ›è¡Œç¬¦æ›¿æ›ç‚ºåˆ†è™Ÿï¼Œä»¥é©æ‡‰ Google Sheet çš„å–®å…ƒæ ¼é¡¯ç¤º\n",
        "        \"ç•¶æ—¥èª²ç¨‹åˆ—è¡¨\": wrap_text(detailed_list.replace('\\n', 'ï¼›'), limit=15),\n",
        "        \"æ”œå¸¶å“\": items_txt, # å¯«å…¥åŸå§‹æ•¸æ“šï¼Œè®“AIæŒ‰éˆ•ç”Ÿæˆç²¾ç…‰ç‰ˆæœ¬\n",
        "        \"å…ˆè®€ç« ç¯€\": read_txt, # å¯«å…¥åŸå§‹æ•¸æ“šï¼Œè®“AIæŒ‰éˆ•ç”Ÿæˆç²¾ç…‰ç‰ˆæœ¬\n",
        "        # æ¸…ç©º AI æ¬„ä½ï¼Œç­‰å¾…å¾ŒçºŒæŒ‰éˆ•æ›´æ–°\n",
        "        \"è¡Œå‰æé†’ä¸€å¥è©±\": \"\",\n",
        "        \"èª²ç¨‹æ‘˜è¦\": \"\",\n",
        "        \"AIå­¸ç¿’å»ºè­°\": \"\",\n",
        "    }\n",
        "    sheet_status = update_weekly_sheet_row(target_weekday, row_data)\n",
        "\n",
        "    title = f\"### ğŸ—“ï¸ æ˜ŸæœŸ{target_weekday} èª²ç¨‹åˆ—è¡¨\\n({sheet_status})\"\n",
        "\n",
        "    # è¿”å›: æ¨™é¡Œ, è©³ç´°èª²ç¨‹åˆ—è¡¨, åºåˆ—åŒ– DataFrame\n",
        "    return title, detailed_list, df_json\n",
        "\n",
        "\n",
        "# === AI å…§å®¹ç”Ÿæˆå‡½å¼ (å·²èª¿æ•´) ===\n",
        "# æ‰€æœ‰çš„ AI å‡½å¼éƒ½ä½¿ç”¨ Upsert æ¨¡å¼ï¼Œåªæ›´æ–°è‡ªå·±è² è²¬çš„æ¬„ä½ã€‚\n",
        "\n",
        "def generate_ai_reminder(df_json, target_weekday):\n",
        "    \"\"\"ç”Ÿæˆ AI è¡Œå‰æé†’ï¼Œä¸¦æ›´æ–° Google Sheet (E æ¬„)ï¼Œæ‡‰ç”¨æ›è¡Œ\"\"\"\n",
        "    if not model:\n",
        "        return \"âŒ Gemini API æœªæˆåŠŸé…ç½®ã€‚\", \"\"\n",
        "    if not df_json:\n",
        "        return \"æœ¬æ—¥ç„¡èª²æˆ–å°šæœªæŸ¥è©¢æ•¸æ“šã€‚\", \"\"\n",
        "\n",
        "    try:\n",
        "        today_df = pd.read_json(io.StringIO(df_json), orient='records')\n",
        "        data_str = today_df.to_string(index=False)\n",
        "    except Exception:\n",
        "        return \"âŒ æ•¸æ“šè§£æå¤±æ•—ã€‚\", \"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    æ ¹æ“šä»¥ä¸‹ä»Šå¤©çš„èª²ç¨‹å®‰æ’å’Œæº–å‚™äº‹é …ï¼Œè«‹æ‰®æ¼”ä¸€ä½è¦ªåˆ‡çš„å­¸ç¿’å¤¥ä¼´ï¼Œ\n",
        "    ç‚ºå­¸ç”Ÿå¯«ä¸€å€‹ç°¡çŸ­ã€æ´»æ½‘ã€å¸¶æœ‰ emoji çš„è¡Œå‰æé†’ã€‚\n",
        "    è«‹å¾ã€Œæ”œå¸¶å“ã€å’Œã€Œå…ˆè®€ç« ç¯€ã€ä¸­æå–é—œéµä¿¡æ¯ï¼Œå°‡å¤šé …å…§å®¹æ•´åˆç‚ºä¸€å¥è©±æˆ–ä¸€æ®µè©±ã€‚\n",
        "    è«‹åªè¼¸å‡ºæé†’å…§å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•å‰ç¶´æˆ–å¾Œç¶´ã€‚\n",
        "    èª²ç¨‹æ¸…å–®ï¼š{data_str}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = model.generate_content(prompt, request_options={\"timeout\": 45})\n",
        "        reminder_raw = response.text.strip()\n",
        "        reminder = wrap_text(reminder_raw, limit=15) # æ‡‰ç”¨æ›è¡Œ\n",
        "\n",
        "        # æ›´æ–° Google Sheet (åªæ›´æ–° è¡Œå‰æé†’ä¸€å¥è©± æ¬„ä½)\n",
        "        row_data = {\"è¡Œå‰æé†’ä¸€å¥è©±\": reminder}\n",
        "        sheet_status = update_weekly_sheet_row(target_weekday, row_data)\n",
        "\n",
        "        return reminder, f\"âœ… AI æé†’å·²ç”Ÿæˆä¸¦å¯«å…¥ Sheetã€‚\\n{sheet_status}\"\n",
        "    except Exception as e:\n",
        "        return f\"âŒ AI æé†’ç”Ÿæˆå¤±æ•—: {e}\", \"âŒ å¯«å…¥ Sheet å¤±æ•—ã€‚\"\n",
        "\n",
        "def generate_course_summary(df_json, target_weekday):\n",
        "    \"\"\"ç”Ÿæˆ AI èª²ç¨‹ä¸»é¡Œæ‘˜è¦ï¼Œä¸¦æ›´æ–° Google Sheet (F æ¬„)ï¼Œæ‡‰ç”¨æ›è¡Œ\"\"\"\n",
        "    if not model:\n",
        "        return \"âŒ Gemini API æœªæˆåŠŸé…ç½®ã€‚\", \"\"\n",
        "    if not df_json:\n",
        "        return \"æœ¬æ—¥ç„¡èª²æˆ–å°šæœªæŸ¥è©¢æ•¸æ“šã€‚\", \"\"\n",
        "\n",
        "    try:\n",
        "        today_df = pd.read_json(io.StringIO(df_json), orient='records')\n",
        "        data_str = today_df.to_string(index=False)\n",
        "    except Exception:\n",
        "        return \"âŒ æ•¸æ“šè§£æå¤±æ•—ã€‚\", \"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    æ ¹æ“šä»¥ä¸‹èª²ç¨‹è³‡è¨Šï¼Œè«‹ç”¨ä¸­æ–‡ç¸½çµã€Œæœ¬æ—¥çš„èª²ç¨‹ä¸»é¡Œå’Œå…§å®¹æ‘˜è¦ã€ã€‚\n",
        "    è«‹ç”¨æ¢åˆ—å¼æˆ–çµæ§‹åŒ–çš„æ–¹å¼å‘ˆç¾ï¼Œä¸è¦è¶…é 150 å­—ã€‚\n",
        "    è«‹åªè¼¸å‡ºæ‘˜è¦å…§å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•å‰ç¶´æˆ–å¾Œç¶´ã€‚\n",
        "    èª²ç¨‹æ¸…å–®ï¼š{data_str}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = model.generate_content(prompt, request_options={\"timeout\": 45})\n",
        "        summary_raw = response.text.strip()\n",
        "        summary = wrap_text(summary_raw, limit=15) # æ‡‰ç”¨æ›è¡Œ\n",
        "\n",
        "        # æ›´æ–° Google Sheet (åªæ›´æ–° èª²ç¨‹æ‘˜è¦ æ¬„ä½)\n",
        "        row_data = {\"èª²ç¨‹æ‘˜è¦\": summary}\n",
        "        sheet_status = update_weekly_sheet_row(target_weekday, row_data)\n",
        "\n",
        "        return summary, f\"âœ… AI èª²ç¨‹æ‘˜è¦å·²ç”Ÿæˆä¸¦å¯«å…¥ Sheetã€‚\\n{sheet_status}\"\n",
        "    except Exception as e:\n",
        "        return f\"âŒ AI èª²ç¨‹ä¸»é¡Œæ‘˜è¦ç”Ÿæˆå¤±æ•—: {e}\", \"âŒ å¯«å…¥ Sheet å¤±æ•—ã€‚\"\n",
        "\n",
        "def generate_learning_suggestion(df_json, target_weekday):\n",
        "    \"\"\"ç”Ÿæˆ AI å­¸ç¿’å»ºè­°ï¼Œä¸¦æ›´æ–° Google Sheet (G æ¬„)ï¼Œæ‡‰ç”¨æ›è¡Œ\"\"\"\n",
        "    if not model:\n",
        "        return \"âŒ Gemini API æœªæˆåŠŸé…ç½®ã€‚\", \"\"\n",
        "    if not df_json:\n",
        "        return \"æœ¬æ—¥ç„¡èª²æˆ–å°šæœªæŸ¥è©¢æ•¸æ“šã€‚\", \"\"\n",
        "\n",
        "    try:\n",
        "        today_df = pd.read_json(io.StringIO(df_json), orient='records')\n",
        "        data_str = today_df.to_string(index=False)\n",
        "    except Exception:\n",
        "        return \"âŒ æ•¸æ“šè§£æå¤±æ•—ã€‚\", \"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    æ ¹æ“šä»¥ä¸‹èª²ç¨‹å®‰æ’å’Œæº–å‚™äº‹é …ï¼Œç‚ºå­¸ç”Ÿæä¾› 2-3 é»å…·é«”çš„ã€Œæœ¬æ—¥å­¸ç¿’å»ºè­°ã€ã€‚\n",
        "    å»ºè­°æ‡‰è‘—é‡æ–¼æ™‚é–“ç®¡ç†ã€èª²é–“ä¼‘æ¯ç­–ç•¥ã€ä»¥åŠå¦‚ä½•æœ€ä½³åŒ–å­¸ç¿’æ•ˆç‡ã€‚\n",
        "    è«‹ç”¨ä¸­æ–‡æ¢åˆ—å¼æ¸…æ™°åœ°å›ç­”ï¼Œä¾‹å¦‚ï¼š1. ... 2. ...ã€‚è«‹åªè¼¸å‡ºå»ºè­°å…§å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•å‰ç¶´æˆ–å¾Œç¶´ã€‚\n",
        "    èª²ç¨‹æ¸…å–®ï¼š{data_str}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = model.generate_content(prompt, request_options={\"timeout\": 45})\n",
        "        suggestion_raw = response.text.strip()\n",
        "        suggestion = wrap_text(suggestion_raw, limit=15) # æ‡‰ç”¨æ›è¡Œ\n",
        "\n",
        "        # æ›´æ–° Google Sheet (åªæ›´æ–° AIå­¸ç¿’å»ºè­° æ¬„ä½)\n",
        "        row_data = {\"AIå­¸ç¿’å»ºè­°\": suggestion}\n",
        "        sheet_status = update_weekly_sheet_row(target_weekday, row_data)\n",
        "\n",
        "        return suggestion, f\"âœ… AI å­¸ç¿’å»ºè­°å·²ç”Ÿæˆä¸¦å¯«å…¥ Sheetã€‚\\n{sheet_status}\"\n",
        "    except Exception as e:\n",
        "        return f\"âŒ AI å­¸ç¿’å»ºè­°ç”Ÿæˆå¤±æ•—: {e}\", \"âŒ å¯«å…¥ Sheet å¤±æ•—ã€‚\"\n",
        "\n",
        "def generate_ai_carry_items(df_json, target_weekday):\n",
        "    \"\"\"æ–°å¢ï¼šç”Ÿæˆ AI æ”œå¸¶å“å»ºè­°ï¼Œä¸¦æ›´æ–° Google Sheet (H æ¬„)\"\"\"\n",
        "    if not model:\n",
        "        return \"âŒ Gemini API æœªæˆåŠŸé…ç½®ã€‚\", \"\"\n",
        "    if not df_json:\n",
        "        return \"æœ¬æ—¥ç„¡èª²æˆ–å°šæœªæŸ¥è©¢æ•¸æ“šã€‚\", \"\"\n",
        "\n",
        "    try:\n",
        "        today_df = pd.read_json(io.StringIO(df_json), orient='records')\n",
        "        items_txt, _ = summarize_courses(today_df, format_type='sheet_raw_items')\n",
        "        data_str = f\"èª²ç¨‹ä¸­æåŠçš„æ”œå¸¶å“åŸå§‹åˆ—è¡¨ï¼š{items_txt}\"\n",
        "    except Exception:\n",
        "        return \"âŒ æ•¸æ“šè§£æå¤±æ•—ã€‚\", \"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    æ ¹æ“šä»¥ä¸‹èª²ç¨‹ä¸­æåŠçš„åŸå§‹æ”œå¸¶å“åˆ—è¡¨ï¼Œè«‹å°‡å…¶æ•´ç†æˆ 2-3 å€‹ç²¾ç°¡çš„ä¸­æ–‡åˆ—é»å¼æ¸…å–®ã€‚\n",
        "    å¦‚æœæ²’æœ‰æåŠå…·é«”ç‰©å“ï¼Œè«‹å»ºè­° 1-2 å€‹å¯¦ç”¨çš„ä¸€èˆ¬å­¸ç¿’ç”¨å“ã€‚\n",
        "    è«‹åªè¼¸å‡ºåˆ—é»å¼æ¸…å–®ï¼Œæ¯å€‹åˆ—é»ä¸è¶…é 10 å€‹ä¸­æ–‡å­—ã€‚\n",
        "    åŸå§‹è³‡æ–™ï¼š{data_str}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = model.generate_content(prompt, request_options={\"timeout\": 45})\n",
        "        items = response.text.strip()\n",
        "\n",
        "        # æ›´æ–° Google Sheet (åªæ›´æ–° æ”œå¸¶å“ æ¬„ä½)\n",
        "        row_data = {\"æ”œå¸¶å“\": items}\n",
        "        sheet_status = update_weekly_sheet_row(target_weekday, row_data)\n",
        "\n",
        "        return items, f\"âœ… AI æ”œå¸¶å“å·²ç”Ÿæˆä¸¦å¯«å…¥ Sheetã€‚\\n{sheet_status}\"\n",
        "    except Exception as e:\n",
        "        return f\"âŒ AI æ”œå¸¶å“ç”Ÿæˆå¤±æ•—: {e}\", \"âŒ å¯«å…¥ Sheet å¤±æ•—ã€‚\"\n",
        "\n",
        "\n",
        "def generate_ai_prereading(df_json, target_weekday):\n",
        "    \"\"\"æ–°å¢ï¼šç”Ÿæˆ AI å…ˆè®€ç« ç¯€å»ºè­°ï¼Œä¸¦æ›´æ–° Google Sheet (I æ¬„)\"\"\"\n",
        "    if not model:\n",
        "        return \"âŒ Gemini API æœªæˆåŠŸé…ç½®ã€‚\", \"\"\n",
        "    if not df_json:\n",
        "        return \"æœ¬æ—¥ç„¡èª²æˆ–å°šæœªæŸ¥è©¢æ•¸æ“šã€‚\", \"\"\n",
        "\n",
        "    try:\n",
        "        today_df = pd.read_json(io.StringIO(df_json), orient='records')\n",
        "        _, read_txt = summarize_courses(today_df, format_type='sheet_raw_items')\n",
        "        data_str = f\"èª²ç¨‹ä¸­æåŠçš„å…ˆè®€ç« ç¯€åŸå§‹åˆ—è¡¨ï¼š{read_txt}\"\n",
        "    except Exception:\n",
        "        return \"âŒ æ•¸æ“šè§£æå¤±æ•—ã€‚\", \"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    æ ¹æ“šä»¥ä¸‹èª²ç¨‹ä¸­æåŠçš„åŸå§‹å…ˆè®€ç« ç¯€åˆ—è¡¨ï¼Œè«‹å°‡å…¶æ•´ç†æˆ 2-3 å€‹ç²¾ç°¡çš„ä¸­æ–‡åˆ—é»å¼é ç¿’é‡é»ã€‚\n",
        "    å¦‚æœæ²’æœ‰æŒ‡å®šç« ç¯€ï¼Œè«‹æä¾› 1-2 å€‹ä¸€èˆ¬æ€§çš„é ç¿’ç­–ç•¥å»ºè­°ã€‚\n",
        "    è«‹åªè¼¸å‡ºåˆ—é»å¼æ¸…å–®ï¼Œæ¯å€‹åˆ—é»ä¸è¶…é 10 å€‹ä¸­æ–‡å­—ã€‚\n",
        "    åŸå§‹è³‡æ–™ï¼š{data_str}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = model.generate_content(prompt, request_options={\"timeout\": 45})\n",
        "        readings = response.text.strip()\n",
        "\n",
        "        # æ›´æ–° Google Sheet (åªæ›´æ–° å…ˆè®€ç« ç¯€ æ¬„ä½)\n",
        "        row_data = {\"å…ˆè®€ç« ç¯€\": readings}\n",
        "        sheet_status = update_weekly_sheet_row(target_weekday, row_data)\n",
        "\n",
        "        return readings, f\"âœ… AI å…ˆè®€ç« ç¯€å·²ç”Ÿæˆä¸¦å¯«å…¥ Sheetã€‚\\n{sheet_status}\"\n",
        "    except Exception as e:\n",
        "        return f\"âŒ AI å…ˆè®€ç« ç¯€ç”Ÿæˆå¤±æ•—: {e}\", \"âŒ å¯«å…¥ Sheet å¤±æ•—ã€‚\"\n",
        "\n",
        "def gemini_analysis():\n",
        "    \"\"\"\n",
        "    å‘¼å« Gemini API é€²è¡Œèª²è¡¨æ•´é«”åˆ†æï¼Œä¸¦å°‡çµæœå¯«å…¥ 'Geminiå»ºè­°' åˆ†é ã€‚\n",
        "    é€™æ˜¯åˆ†é  3 çš„æ ¸å¿ƒåŠŸèƒ½ã€‚\n",
        "    \"\"\"\n",
        "    if not model:\n",
        "        return \"âŒ Gemini API æœªæˆåŠŸé…ç½®ï¼Œç„¡æ³•é€²è¡Œåˆ†æã€‚\"\n",
        "    if not worksheet or not suggestion_ws:\n",
        "        return \"âŒ Google Sheets æœªæˆåŠŸé€£ç·šï¼Œç„¡æ³•è®€å–è³‡æ–™æˆ–å¯«å…¥å»ºè­°ã€‚\"\n",
        "\n",
        "    now = dt.datetime.now(TW_TZ).strftime(\"%Y-%m-%d %H:%M\")\n",
        "    analysis_result = \"\"\n",
        "    feedback = \"\"\n",
        "\n",
        "    try:\n",
        "        all_data = worksheet.get_all_values()\n",
        "        if not all_data or len(all_data) < 2:\n",
        "            analysis_result = \"èª²è¡¨ä¸­ç›®å‰æ²’æœ‰è³‡æ–™ï¼Œç„¡æ³•åˆ†æã€‚\"\n",
        "            feedback = analysis_result\n",
        "\n",
        "            # å¯«å…¥ç‹€æ…‹åˆ°å»ºè­°è¡¨\n",
        "            suggestion_ws.append_row([now, \"æ•´é«”èª²è¡¨åˆ†æ\", analysis_result], value_input_option=\"USER_ENTERED\")\n",
        "            return analysis_result + f\"\\n\\n---\\nâœ… åˆ†æç‹€æ…‹å·²å¯«å…¥ '{suggestion_ws.title}' åˆ†é ã€‚\"\n",
        "\n",
        "\n",
        "        df = pd.DataFrame(all_data[1:], columns=all_data[0])\n",
        "\n",
        "        # æº–å‚™å‚³çµ¦ Gemini çš„æ•¸æ“šï¼ˆæ•´å€‹èª²è¡¨ï¼‰\n",
        "        preview = df.to_string(index=False)\n",
        "        prompt = f\"\"\"\n",
        "        é€™æ˜¯ä¸€ä»½å­¸ç”Ÿçš„èª²è¡¨ï¼ŒåŒ…å«èª²ç¨‹åç¨±ã€æ˜ŸæœŸã€ä¸Šèª²æ™‚é–“ã€ä¸Šèª²æ•™å®¤ã€æ”œå¸¶å“å’Œå…ˆè®€ç« ç¯€ç­‰è³‡è¨Šï¼š\n",
        "        {preview}\n",
        "\n",
        "        è«‹æ“”ä»»å­¸ç¿’é¡§å•ï¼Œæ ¹æ“šé€™ä»½èª²è¡¨ï¼š\n",
        "        1. æ•´ç†å‡ºå­¸ç”Ÿä¸€é€±çš„å­¸ç¿’è¶¨å‹¢ï¼Œä¾‹å¦‚å“ªå¤©èª²ç¨‹æœ€å¯†é›†ã€æ˜¯å¦æœ‰éœ€è¦ç‰¹åˆ¥æ³¨æ„çš„é€£å ‚èª²ã€‚\n",
        "        2. é‡å°ã€Œæ”œå¸¶å“ã€å’Œã€Œå…ˆè®€ç« ç¯€ã€çµ¦å‡ºç¶œåˆçš„ã€å…·é«”çš„æº–å‚™å»ºè­°ï¼ˆä¸åªæ˜¯åˆ—å‡ºæ¸…å–®ï¼Œè€Œæ˜¯å¦‚ä½•æº–å‚™ï¼‰ã€‚\n",
        "        3. é‡å°æ•´é«”èª²è¡¨ï¼Œçµ¦å‡º 2-3 å€‹æ™‚é–“ç®¡ç†æˆ–å­¸ç¿’æ–¹æ³•ä¸Šçš„å»ºè­°ã€‚\n",
        "        è«‹ç”¨ä¸­æ–‡æ¢åˆ—å¼æ¸…æ™°åœ°å›ç­”ã€‚\n",
        "        \"\"\"\n",
        "\n",
        "        # API Call\n",
        "        response = model.generate_content(prompt, request_options={\"timeout\": 60})\n",
        "        analysis_result = response.text.strip()\n",
        "        feedback = \"âœ… Gemini åˆ†ææˆåŠŸï¼\"\n",
        "\n",
        "    except Exception as e:\n",
        "        # æ•ç² API éŒ¯èª¤\n",
        "        analysis_result = f\"âŒ Gemini åˆ†ææ™‚ç™¼ç”Ÿ API éŒ¯èª¤ï¼š{e}\"\n",
        "        feedback = analysis_result\n",
        "\n",
        "    # å¯«å…¥çµæœ (åˆ†ææˆ–éŒ¯èª¤) åˆ° Google Sheet 'Geminiå»ºè­°'\n",
        "    try:\n",
        "        item_description = \"æ•´é«”èª²è¡¨åˆ†æ\"\n",
        "        # å°‡çµæœåˆ†è¡Œå­˜å…¥ Google Sheet çš„å„²å­˜æ ¼ï¼Œä»¥ä¿ç•™æ ¼å¼ (æ³¨æ„ï¼šå–®ä¸€å„²å­˜æ ¼æœ‰å­—æ•¸é™åˆ¶)\n",
        "        suggestion_ws.append_row([now, item_description, analysis_result], value_input_option=\"USER_ENTERED\")\n",
        "        feedback += f\"\\nâœ… åˆ†æçµæœå·²å¯«å…¥ '{suggestion_ws.title}' åˆ†é ã€‚\"\n",
        "    except Exception as e:\n",
        "        feedback += f\"\\nâŒ å¯«å…¥ '{SHEET_GEMINI_SUGGESTION}' åˆ†é å¤±æ•—ï¼š{e}\"\n",
        "\n",
        "    # è¿”å›å®Œæ•´çš„åˆ†ææ–‡æœ¬ï¼Œä¸¦åœ¨ä¸‹æ–¹é™„å¸¶å›é¥‹è¨Šæ¯\n",
        "    return analysis_result + \"\\n\\n---\\n\" + feedback\n",
        "\n",
        "\n",
        "# === æ–°å¢ï¼šPDF è§£æèˆ‡ä¸Šå‚³åŠŸèƒ½ (ä¿æŒä¸è®Š) ===\n",
        "def upload_and_process_pdf(pdf_file_path):\n",
        "    \"\"\"\n",
        "    æ¥æ”¶ PDF æª”æ¡ˆè·¯å¾‘ï¼Œä½¿ç”¨ Gemini è§£æå…§å®¹ç‚ºèª²è¡¨çµæ§‹ï¼Œ\n",
        "    ä¸¦å°‡çµæœä»¥ DataFrame å‘ˆç¾ï¼ŒåŒæ™‚å¯«å…¥ Google Sheet çš„ã€Œä¸Šå‚³æ–°èª²è¡¨ã€åˆ†é ã€‚\n",
        "    \"\"\"\n",
        "    df_empty = pd.DataFrame(columns=[\"èª²ç¨‹åç¨±\", \"ä¸Šèª²æ•™å®¤\", \"æ˜ŸæœŸ\", \"ç¯€æ¬¡\", \"ä¸Šèª²æ™‚é–“\"])\n",
        "\n",
        "    if not pdf_file_path:\n",
        "        return \"âŒ å°šæœªä¸Šå‚³æª”æ¡ˆ\", df_empty\n",
        "    if not PdfReader:\n",
        "        err_msg = \"âŒ pypdf å‡½å¼åº«æœªå®‰è£ï¼Œç„¡æ³•è®€å– PDF å…§å®¹ã€‚è«‹å…ˆåŸ·è¡Œ !pip install pypdf\"\n",
        "        return err_msg, df_empty\n",
        "    if not model:\n",
        "        err_msg = \"âŒ Gemini API æœªæˆåŠŸé…ç½®ï¼Œç„¡æ³•é€²è¡Œ PDF è§£æã€‚\"\n",
        "        return err_msg, df_empty\n",
        "    if not new_timetable_ws:\n",
        "        err_msg = \"âŒ Google Sheets 'ä¸Šå‚³æ–°èª²è¡¨' åˆ†é æœªæˆåŠŸé€£ç·šã€‚è«‹æª¢æŸ¥é€£ç·šè¨­å®šã€‚\"\n",
        "        return err_msg, df_empty\n",
        "\n",
        "    status_msg = \"\"\n",
        "    extracted_text = \"\"\n",
        "    required_columns = [\"èª²ç¨‹åç¨±\", \"ä¸Šèª²æ•™å®¤\", \"æ˜ŸæœŸ\", \"ç¯€æ¬¡\", \"ä¸Šèª²æ™‚é–“\"]\n",
        "\n",
        "    try:\n",
        "        # 1. è®€å– PDF å…§å®¹\n",
        "        reader = PdfReader(pdf_file_path)\n",
        "        for i, page in enumerate(reader.pages):\n",
        "            extracted_text += f\"--- Page {i+1} ---\\n\"\n",
        "            extracted_text += page.extract_text() or \"(ç„¡æ³•æå–æ–‡å­—)\"\n",
        "            extracted_text += \"\\n\\n\"\n",
        "\n",
        "        if not extracted_text.strip():\n",
        "            status_msg = \"âŒ PDF æª”æ¡ˆä¸­æœªè®€å–åˆ°ä»»ä½•æ–‡å­—å…§å®¹ï¼Œå¯èƒ½ç‚ºåœ–ç‰‡æƒææª”æˆ–æ ¼å¼ä¸æ”¯æ´ã€‚\"\n",
        "            return status_msg, df_empty\n",
        "\n",
        "        # 2. æº–å‚™ Gemini æç¤ºè© (è¦æ±‚çµæ§‹åŒ–è¼¸å‡º - CSV)\n",
        "        prompt = f\"\"\"\n",
        "        è«‹åˆ†æä»¥ä¸‹å¾èª²è¡¨ PDF ä¸­æå–å‡ºçš„æ–‡å­—å…§å®¹ã€‚ä½ çš„ä»»å‹™æ˜¯å°‡èª²ç¨‹è³‡è¨Šæ•´ç†æˆä¸€å€‹æ¨™æº–çš„ CSV æ ¼å¼ã€‚\n",
        "        è«‹åš´æ ¼ç¢ºä¿è¼¸å‡ºå…§å®¹**åªæœ‰** CSV æ ¼å¼çš„æ•¸æ“šï¼Œä¸åŒ…å«ä»»ä½•é¡å¤–èªªæ˜æ–‡å­—æˆ–Markdownæ¨™è¨˜ (å¦‚ ```csv)ã€‚\n",
        "\n",
        "        CSV çš„æ¨™é ­è¡Œ (Header) **å¿…é ˆ**å®Œå…¨åŒ…å«ä»¥ä¸‹æ¬„ä½ï¼Œä¸”é †åºä¸è®Šï¼š\n",
        "        {','.join(required_columns)}\n",
        "\n",
        "        è«‹æ ¹æ“š PDF å…§å®¹ï¼Œå°‡èª²è¡¨æ•¸æ“šå¡«å…¥é€™äº›æ¬„ä½ã€‚\n",
        "        æ˜ŸæœŸè«‹å‹™å¿…ç”¨ä¸­æ–‡æ•¸å­—ã€Œä¸€ã€äºŒã€ä¸‰ã€å››ã€äº”ã€å…­ã€æ—¥ã€è¡¨ç¤ºã€‚\n",
        "        --- PDF å…§å®¹é–‹å§‹ ---\n",
        "        {extracted_text.strip()}\n",
        "        --- PDF å…§å®¹çµæŸ ---\n",
        "        \"\"\"\n",
        "\n",
        "        # 3. å‘¼å« Gemini API é€²è¡Œçµæ§‹åŒ–è§£æ\n",
        "        response = model.generate_content(prompt, request_options={\"timeout\": 120})\n",
        "        csv_text = response.text.strip()\n",
        "\n",
        "        # ç§»é™¤å¯èƒ½çš„ Markdown æ¨™è¨˜ï¼Œä¾‹å¦‚ ```csv æˆ– ```\n",
        "        csv_text = csv_text.replace(\"```csv\", \"\").replace(\"```\", \"\").strip()\n",
        "\n",
        "        # 4. å°‡ CSV æ–‡æœ¬è½‰æ›ç‚º DataFrame\n",
        "        df_parsed = pd.read_csv(io.StringIO(csv_text))\n",
        "\n",
        "        # 5. é©—è­‰èˆ‡æ•´ç† DataFrame\n",
        "        if not all(col in df_parsed.columns for col in required_columns):\n",
        "            missing_cols = [col for col in required_columns if col not in df_parsed.columns]\n",
        "            raise ValueError(f\"Gemini è¼¸å‡ºçš„æ¬„ä½ä¸å®Œæ•´æˆ–ä¸æ­£ç¢ºã€‚ç¼ºå°‘æ¬„ä½: {missing_cols}\")\n",
        "\n",
        "        # åªä¿ç•™æ‰€éœ€æ¬„ä½ä¸¦ç¢ºä¿é †åº\n",
        "        df_final = df_parsed[required_columns].copy()\n",
        "\n",
        "        # 6. å¯«å…¥ Google Sheets\n",
        "        new_timetable_ws.clear()\n",
        "        new_timetable_ws.append_row(required_columns, value_input_option=\"USER_ENTERED\")\n",
        "        set_with_dataframe(new_timetable_ws, df_final, include_column_header=False, include_index=False)\n",
        "\n",
        "        status_msg = f\"âœ… PDF èª²è¡¨è§£ææˆåŠŸï¼å·²å°‡ {len(df_final)} ç­†è³‡æ–™å¯«å…¥ '{SHEET_UPLOAD_NEW}' åˆ†é ï¼Œä¸¦é¡¯ç¤ºæ–¼ä¸‹æ–¹é è¦½ã€‚\"\n",
        "\n",
        "        return status_msg, df_final\n",
        "\n",
        "    except Exception as e:\n",
        "        error_details = traceback.format_exc()\n",
        "        status_msg = f\"âŒ è™•ç† PDF æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}\\n\\nè«‹æª¢æŸ¥ PDF æ ¼å¼æˆ– Gemini API è¼¸å‡ºã€‚\\nè©³ç´°éŒ¯èª¤è«‹è¦‹æ§åˆ¶å°ã€‚\"\n",
        "        print(f\"--- ERROR DETAILS ---\\n{error_details}\\n---------------------\")\n",
        "        return status_msg, df_empty\n",
        "\n",
        "\n",
        "# === Gradio ä»‹é¢ ===\n",
        "with gr.Blocks(title=\"æ™ºæ…§èª²è¡¨æŸ¥çœ‹ç³»çµ±\") as demo:\n",
        "    gr.Markdown(\"# ğŸ“ æ™ºæ…§èª²è¡¨æŸ¥çœ‹ç³»çµ±ï¼ˆAI å¼·åŒ–ç‰ˆï¼‰\")\n",
        "    gr.Markdown(\"æ–°å¢ PDF è§£æã€AI èª²è¡¨åˆ†æï¼Œä»¥åŠ AI èª²ç¨‹ä¸»é¡Œæ‘˜è¦èˆ‡è¡Œå‰æé†’åŠŸèƒ½ã€‚\")\n",
        "\n",
        "    # éš±è—ç‹€æ…‹ï¼Œç”¨æ–¼åœ¨ä¸åŒæŒ‰éˆ•é»æ“Šä¹‹é–“å‚³è¼¸ç•¶æ—¥èª²ç¨‹ DataFrame\n",
        "    day_df_json_state = gr.State(\"\")\n",
        "    query_weekday_state = gr.State(\"\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "\n",
        "        # --- åˆ†é 1ï¼šä¸Šå‚³ PDF ---\n",
        "        with gr.Tab(\"ğŸ“¤ ä¸Šå‚³èª²è¡¨ PDF\"):\n",
        "            gr.Markdown(\"### ğŸ“„ è§£æ PDF èª²è¡¨ä¸¦å¯«å…¥ã€Œä¸Šå‚³æ–°èª²è¡¨ã€åˆ†é \")\n",
        "            pdf_file = gr.File(label=\"è«‹ä¸Šå‚³èª²è¡¨ PDF æª”æ¡ˆ\", file_types=[\".pdf\"])\n",
        "            upload_btn = gr.Button(\"è§£æ PDF ä¸¦å¯«å…¥ Google Sheets\")\n",
        "            upload_output = gr.Markdown()\n",
        "            df_output = gr.Dataframe(\n",
        "                label=\"è§£æå¾Œçš„èª²è¡¨é è¦½ (å¯«å…¥ 'ä¸Šå‚³æ–°èª²è¡¨' åˆ†é )\",\n",
        "                headers=[\"èª²ç¨‹åç¨±\", \"ä¸Šèª²æ•™å®¤\", \"æ˜ŸæœŸ\", \"ç¯€æ¬¡\", \"ä¸Šèª²æ™‚é–“\"],\n",
        "                datatype=[\"str\", \"str\", \"str\", \"str\", \"str\"],\n",
        "                wrap=True,\n",
        "            )\n",
        "            upload_btn.click(\n",
        "                upload_and_process_pdf,\n",
        "                inputs=[pdf_file],\n",
        "                outputs=[upload_output, df_output]\n",
        "            )\n",
        "\n",
        "        # --- åˆ†é 2ï¼šæŸ¥è©¢èª²ç¨‹ (æ–°å¢ AI åŠŸèƒ½) ---\n",
        "        with gr.Tab(\"ğŸ“… æŸ¥è©¢èª²ç¨‹\"):\n",
        "            with gr.Column():\n",
        "                weekday_dropdown = gr.Dropdown(\n",
        "                    label=\"é¸æ“‡æ˜ŸæœŸ\",\n",
        "                    choices=[\"ä¸€\",\"äºŒ\",\"ä¸‰\",\"å››\",\"äº”\",\"å…­\",\"æ—¥\"],\n",
        "                    value=\"ä¸‰\"\n",
        "                )\n",
        "                query_btn = gr.Button(\"æŸ¥è©¢èª²ç¨‹ä¸¦æº–å‚™ AI åˆ†æ\")\n",
        "\n",
        "                output_title = gr.Markdown()\n",
        "                output_detailed_list = gr.Textbox(label=\"ç•¶æ—¥èª²ç¨‹è©³ç´°åˆ—è¡¨ (æ ¼å¼: èª²ç¨‹åç¨±ä¸Šèª²æ•™å®¤ç¯€æ¬¡ä¸Šèª²æ™‚é–“)\", lines=10, type=\"text\", interactive=False)\n",
        "\n",
        "                # åˆå§‹æŸ¥è©¢åªæ›´æ–°èª²ç¨‹åˆ—è¡¨å’Œéš±è—ç‹€æ…‹\n",
        "                query_btn.click(\n",
        "                    query_day_data,\n",
        "                    inputs=[weekday_dropdown],\n",
        "                    outputs=[output_title, output_detailed_list, day_df_json_state],\n",
        "                    # æ›´æ–° state\n",
        "                ).then(\n",
        "                    lambda w: w, # åƒ…å°‡æ˜ŸæœŸå€¼å‚³å…¥ state\n",
        "                    inputs=[weekday_dropdown],\n",
        "                    outputs=[query_weekday_state]\n",
        "                )\n",
        "\n",
        "                gr.Markdown(\"---\")\n",
        "                gr.Markdown(\"### ğŸ§  AI èª²ç¨‹æº–å‚™èˆ‡å»ºè­° (çµæœå°‡å¯«å…¥ã€æœ¬é€±é‡é»ã€)\")\n",
        "\n",
        "                # --- AI è¡Œå‰æé†’ ---\n",
        "                ai_reminder_btn = gr.Button(\"âœ¨ ç”Ÿæˆ AI è¡Œå‰æé†’ (èªæ°£æ´»æ½‘)\")\n",
        "                ai_reminder_output = gr.Textbox(label=\"ğŸ“£ è¡Œå‰æé†’ä¸€å¥è©±\", lines=3, type=\"text\", interactive=False)\n",
        "                ai_reminder_status = gr.Markdown()\n",
        "                ai_reminder_btn.click(\n",
        "                    generate_ai_reminder,\n",
        "                    inputs=[day_df_json_state, query_weekday_state],\n",
        "                    outputs=[ai_reminder_output, ai_reminder_status]\n",
        "                )\n",
        "\n",
        "                # --- AI èª²ç¨‹ä¸»é¡Œæ‘˜è¦ ---\n",
        "                ai_summary_btn = gr.Button(\"ğŸ“ ç”Ÿæˆ AI èª²ç¨‹ä¸»é¡Œæ‘˜è¦\")\n",
        "                ai_summary_output = gr.Textbox(label=\"ğŸ“ èª²ç¨‹æ‘˜è¦\", lines=5, type=\"text\", interactive=False)\n",
        "                ai_summary_status = gr.Markdown()\n",
        "                ai_summary_btn.click(\n",
        "                    generate_course_summary,\n",
        "                    inputs=[day_df_json_state, query_weekday_state],\n",
        "                    outputs=[ai_summary_output, ai_summary_status]\n",
        "                )\n",
        "\n",
        "                # --- AI å­¸ç¿’å»ºè­° ---\n",
        "                ai_suggestion_btn = gr.Button(\"ğŸ’¡ ç”Ÿæˆ AI å­¸ç¿’å»ºè­°\")\n",
        "                ai_suggestion_output = gr.Textbox(label=\"ğŸ’¡ AI å­¸ç¿’å»ºè­°\", lines=5, type=\"text\", interactive=False)\n",
        "                ai_suggestion_status = gr.Markdown()\n",
        "                ai_suggestion_btn.click(\n",
        "                    generate_learning_suggestion,\n",
        "                    inputs=[day_df_json_state, query_weekday_state],\n",
        "                    outputs=[ai_suggestion_output, ai_suggestion_status]\n",
        "                )\n",
        "\n",
        "                # --- æ–°å¢ï¼šAI æ”œå¸¶å“ ---\n",
        "                ai_carry_btn = gr.Button(\"ğŸ’ ç”Ÿæˆ AI æ”œå¸¶å“å»ºè­°\")\n",
        "                ai_carry_output = gr.Textbox(label=\"ğŸ’ æ”œå¸¶å“ (åˆ—é»å¼)\", lines=3, type=\"text\", interactive=False)\n",
        "                ai_carry_status = gr.Markdown()\n",
        "                ai_carry_btn.click(\n",
        "                    generate_ai_carry_items,\n",
        "                    inputs=[day_df_json_state, query_weekday_state],\n",
        "                    outputs=[ai_carry_output, ai_carry_status]\n",
        "                )\n",
        "\n",
        "                # --- æ–°å¢ï¼šAI å…ˆè®€ç« ç¯€ ---\n",
        "                ai_preread_btn = gr.Button(\"ğŸ“– ç”Ÿæˆ AI å…ˆè®€ç« ç¯€å»ºè­°\")\n",
        "                ai_preread_output = gr.Textbox(label=\"ğŸ“– å…ˆè®€ç« ç¯€ (åˆ—é»å¼)\", lines=3, type=\"text\", interactive=False)\n",
        "                ai_preread_status = gr.Markdown()\n",
        "                ai_preread_btn.click(\n",
        "                    generate_ai_prereading,\n",
        "                    inputs=[day_df_json_state, query_weekday_state],\n",
        "                    outputs=[ai_preread_output, ai_preread_status]\n",
        "                )\n",
        "\n",
        "\n",
        "        # --- åˆ†é 3ï¼šGemini åˆ†æå»ºè­° (å·²å®Œæˆ) ---\n",
        "        with gr.Tab(\"ğŸ¤– AI èª²è¡¨æ•´é«”åˆ†æ\"):\n",
        "            gr.Markdown(\"### ğŸ§  æ ¹æ“šæ‚¨çš„å®Œæ•´èª²è¡¨é€²è¡Œå­¸ç¿’è¶¨å‹¢èˆ‡æº–å‚™å»ºè­°åˆ†æ\")\n",
        "            ai_btn = gr.Button(\"ç”¢ç”Ÿ AI åˆ†æå»ºè­°\")\n",
        "            ai_output = gr.Textbox(label=\"Gemini åˆ†æçµæœèˆ‡å›é¥‹\", lines=15)\n",
        "\n",
        "            ai_btn.click(fn=gemini_analysis, inputs=None, outputs=ai_output)\n",
        "\n",
        "# å•Ÿå‹• Gradio App\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=True, share=True, inline=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "hpxuxjnQAlJP",
        "outputId": "3cb91002-c7de-4c14-aa76-a27b90aaa279"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Google Sheets é€£ç·šæˆåŠŸã€‚\n",
            "âœ… Gemini API é…ç½®æˆåŠŸã€‚\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://53581eedeb3a6cd5aa.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://53581eedeb3a6cd5aa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://53581eedeb3a6cd5aa.gradio.live\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhHvNZBimvmZOQDQdkffRq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}